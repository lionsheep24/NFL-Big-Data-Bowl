{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from kaggle.competitions import nflrush\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "from string import punctuation\n",
    "import re\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "#Modeling\n",
    "#https://www.kaggle.com/bestpredict/location-eda-8eb410\n",
    "import os\n",
    "TRAIN_ABLE_FALSE=True\n",
    "if TRAIN_ABLE_FALSE:\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = \"1\"\n",
    "\n",
    "import sklearn.metrics as mtr\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.layers import Dense,Input,Flatten,concatenate,Dropout,Lambda,BatchNormalization\n",
    "from keras import optimizers\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "from keras.callbacks import Callback\n",
    "from  keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "\n",
    "TRAIN_OFFLINE = False\n",
    "\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6.39 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train = pd.read_csv('./data/train.csv', dtype={'WindSpeed': 'object'})\n",
    "train =  pd.DataFrame(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tools for Preprocessing\n",
    "\n",
    "def clean_StadiumType(txt):\n",
    "    if pd.isna(txt):\n",
    "        return np.nan\n",
    "    txt = txt.lower()\n",
    "    txt = ''.join([c for c in txt if c not in punctuation])\n",
    "    txt = re.sub(' +', ' ', txt)\n",
    "    txt = txt.strip()\n",
    "    txt = txt.replace('outside', 'outdoor')\n",
    "    txt = txt.replace('outdor', 'outdoor')\n",
    "    txt = txt.replace('outddors', 'outdoor')\n",
    "    txt = txt.replace('outdoors', 'outdoor')\n",
    "    txt = txt.replace('oudoor', 'outdoor')\n",
    "    txt = txt.replace('indoors', 'indoor')\n",
    "    txt = txt.replace('ourdoor', 'outdoor')\n",
    "    txt = txt.replace('retractable', 'rtr.')\n",
    "    return txt\n",
    "\n",
    "def transform_StadiumType(txt):\n",
    "    if pd.isna(txt):\n",
    "        return np.nan\n",
    "    if 'outdoor' in txt or 'open' in txt:\n",
    "        return 2\n",
    "    if 'indoor' in txt or 'closed' in txt:\n",
    "        return 0\n",
    "    if 'dome' in txt:\n",
    "        return 1\n",
    "    \n",
    "    return np.nan\n",
    "\n",
    "Turf = {'Field Turf':1, 'A-Turf Titan':1, 'Grass':0, 'UBU Sports Speed S5-M':1, \n",
    "        'Artificial':1, 'DD GrassMaster':1, 'Natural Grass':0, \n",
    "        'UBU Speed Series-S5-M':1, 'FieldTurf':1, 'FieldTurf 360':1, 'Natural grass':0, 'grass':0, \n",
    "        'Natural':0, 'Artifical':1, 'FieldTurf360':1, 'Naturall Grass':0, 'Field turf':1, \n",
    "        'SISGrass':1, 'Twenty-Four/Seven Turf':1, 'natural grass':0} \n",
    "\n",
    "def str_to_float(txt):\n",
    "    try:\n",
    "        return float(txt)\n",
    "    except:\n",
    "        return -1\n",
    "    \n",
    "def clean_WindDirection(txt):\n",
    "    if pd.isna(txt):\n",
    "        return np.nan\n",
    "    txt = txt.lower()\n",
    "    txt = ''.join([c for c in txt if c not in punctuation])\n",
    "    txt = txt.replace('from', '')\n",
    "    txt = txt.replace(' ', '')\n",
    "    txt = txt.replace('north', 'N')\n",
    "    txt = txt.replace('south', 'S')\n",
    "    txt = txt.replace('west', 'W')\n",
    "    txt = txt.replace('east', 'E')\n",
    "    return txt\n",
    "\n",
    "def transform_WindDirection(txt):\n",
    "    if pd.isna(txt):\n",
    "        return np.nan\n",
    "    \n",
    "    if txt=='n':\n",
    "        return 0\n",
    "    if txt=='nne' or txt=='nen':\n",
    "        return 1/8\n",
    "    if txt=='ne':\n",
    "        return 2/8\n",
    "    if txt=='ene' or txt=='nee':\n",
    "        return 3/8\n",
    "    if txt=='e':\n",
    "        return 4/8\n",
    "    if txt=='ese' or txt=='see':\n",
    "        return 5/8\n",
    "    if txt=='se':\n",
    "        return 6/8\n",
    "    if txt=='ses' or txt=='sse':\n",
    "        return 7/8\n",
    "    if txt=='s':\n",
    "        return 8/8\n",
    "    if txt=='ssw' or txt=='sws':\n",
    "        return 9/8\n",
    "    if txt=='sw':\n",
    "        return 10/8\n",
    "    if txt=='sww' or txt=='wsw':\n",
    "        return 11/8\n",
    "    if txt=='w':\n",
    "        return 12/8\n",
    "    if txt=='wnw' or txt=='nww':\n",
    "        return 13/8\n",
    "    if txt=='nw':\n",
    "        return 14/8\n",
    "    if txt=='nwn' or txt=='nnw':\n",
    "        return 15/8\n",
    "    return np.nan\n",
    "\n",
    "def map_weather(txt):\n",
    "    ans = 1\n",
    "    if pd.isna(txt):\n",
    "        return 0\n",
    "    if 'partly' in txt:\n",
    "        ans*=0.5\n",
    "    if 'climate controlled' in txt or 'indoor' in txt:\n",
    "        return ans*3\n",
    "    if 'sunny' in txt or 'sun' in txt:\n",
    "        return ans*2\n",
    "    if 'clear' in txt:\n",
    "        return ans\n",
    "    if 'cloudy' in txt:\n",
    "        return -ans\n",
    "    if 'rain' in txt or 'rainy' in txt:\n",
    "        return -2*ans\n",
    "    if 'snow' in txt:\n",
    "        return -3*ans\n",
    "    return 0\n",
    "\n",
    "def OffensePersonnelSplit(x):\n",
    "    dic = {'DB' : 0, 'DL' : 0, 'LB' : 0, 'OL' : 0, 'QB' : 0, 'RB' : 0, 'TE' : 0, 'WR' : 0}\n",
    "    for xx in x.split(\",\"):\n",
    "        xxs = xx.split(\" \")\n",
    "        dic[xxs[-1]] = int(xxs[-2])\n",
    "    return dic\n",
    "\n",
    "def DefensePersonnelSplit(x):\n",
    "    dic = {'DB' : 0, 'DL' : 0, 'LB' : 0, 'OL' : 0}\n",
    "    for xx in x.split(\",\"):\n",
    "        xxs = xx.split(\" \")\n",
    "        dic[xxs[-1]] = int(xxs[-2])\n",
    "    return dic\n",
    "\n",
    "def YardGain(train):\n",
    "    YG = 0\n",
    "    if train['YardLine'] == 50:\n",
    "        YG = 50\n",
    "    #Home team offense at home field\n",
    "    elif (train['FieldPosition'] == train['HomeTeamAbbr']) & (train['isOffenseHome'] == True):\n",
    "        YG = train['YardLine']\n",
    "    #Home team offense at away field\n",
    "    elif (train['FieldPosition'] == train['VisitorTeamAbbr']) & (train['isOffenseHome'] == True):\n",
    "        YG = 100 - train['YardLine']\n",
    "    #Away team offense at away field\n",
    "    elif (train['FieldPosition'] == train['VisitorTeamAbbr']) & (train['isOffenseHome'] == False):    \n",
    "        YG = train['YardLine']\n",
    "    #Away team offense at home field\n",
    "    elif (train['FieldPosition'] == train['HomeTeamAbbr']) & (train['isOffenseHome'] == False):\n",
    "        YG = 100 - train['YardLine']\n",
    "    return YG\n",
    "\n",
    "def DistanceFromScrimmageLine(Df):\n",
    "    Distance = 0\n",
    "    if Df.PlayDirection == 'left':\n",
    "        Distance = - (10 + Df['OffenseYardLine'] - (120 - Df['X_Rusher']))\n",
    "    if Df.PlayDirection == 'right':\n",
    "        Distance = - (10 + Df['OffenseYardLine'] - (Df['X_Rusher']))\n",
    "    return Distance\n",
    "\n",
    "import matplotlib.patches as patches\n",
    "def PlayVisualization(linenumbers=True,\n",
    "                          endzones=True,\n",
    "                          highlight_line=False,\n",
    "                          highlight_line_number=50,\n",
    "                          highlighted_name='Line of Scrimmage',\n",
    "                          fifty_is_los=False,\n",
    "                          figsize=(12, 6.33)):\n",
    "    \"\"\"\n",
    "    Function that plots the football field for viewing plays.\n",
    "    Allows for showing or hiding endzones.\n",
    "    \"\"\"\n",
    "    rect = patches.Rectangle((0, 0), 120, 53.3, linewidth=0.1,\n",
    "                             edgecolor='r', facecolor='darkgreen', zorder=0)\n",
    "\n",
    "    fig, ax = plt.subplots(1, figsize=figsize)\n",
    "    ax.add_patch(rect)\n",
    "\n",
    "    plt.plot([10, 10, 10, 20, 20, 30, 30, 40, 40, 50, 50, 60, 60, 70, 70, 80,\n",
    "              80, 90, 90, 100, 100, 110, 110, 120, 0, 0, 120, 120],\n",
    "             [0, 0, 53.3, 53.3, 0, 0, 53.3, 53.3, 0, 0, 53.3, 53.3, 0, 0, 53.3,\n",
    "              53.3, 0, 0, 53.3, 53.3, 0, 0, 53.3, 53.3, 53.3, 0, 0, 53.3],\n",
    "             color='white')\n",
    "    if fifty_is_los:\n",
    "        plt.plot([60, 60], [0, 53.3], color='gold')\n",
    "        plt.text(62, 50, '<- Player Yardline at Snap', color='gold')\n",
    "    # Endzones\n",
    "    if endzones:\n",
    "        ez1 = patches.Rectangle((0, 0), 10, 53.3,\n",
    "                                linewidth=0.1,\n",
    "                                edgecolor='r',\n",
    "                                facecolor='blue',\n",
    "                                alpha=0.2,\n",
    "                                zorder=0)\n",
    "        ez2 = patches.Rectangle((110, 0), 120, 53.3,\n",
    "                                linewidth=0.1,\n",
    "                                edgecolor='r',\n",
    "                                facecolor='blue',\n",
    "                                alpha=0.2,\n",
    "                                zorder=0)\n",
    "        ax.add_patch(ez1)\n",
    "        ax.add_patch(ez2)\n",
    "    plt.xlim(0, 120)\n",
    "    plt.ylim(-5, 58.3)\n",
    "    plt.axis('off')\n",
    "    if linenumbers:\n",
    "        for x in range(20, 110, 10):\n",
    "            numb = x\n",
    "            if x > 50:\n",
    "                numb = 120 - x\n",
    "            plt.text(x, 5, str(numb - 10),\n",
    "                     horizontalalignment='center',\n",
    "                     fontsize=20,  # fontname='Arial',\n",
    "                     color='white')\n",
    "            plt.text(x - 0.95, 53.3 - 5, str(numb - 10),\n",
    "                     horizontalalignment='center',\n",
    "                     fontsize=20,  # fontname='Arial',\n",
    "                     color='white', rotation=180)\n",
    "    if endzones:\n",
    "        hash_range = range(11, 110)\n",
    "    else:\n",
    "        hash_range = range(1, 120)\n",
    "\n",
    "    for x in hash_range:\n",
    "        ax.plot([x, x], [0.4, 0.7], color='white')\n",
    "        ax.plot([x, x], [53.0, 52.5], color='white')\n",
    "        ax.plot([x, x], [22.91, 23.57], color='white')\n",
    "        ax.plot([x, x], [29.73, 30.39], color='white')\n",
    "\n",
    "    if highlight_line:\n",
    "        hl = highlight_line_number + 10\n",
    "        plt.plot([hl, hl], [0, 53.3], color='yellow')\n",
    "        plt.text(hl + 2, 50, '<- {}'.format(highlighted_name),\n",
    "                 color='yellow')\n",
    "    return fig, ax\n",
    "\n",
    "def TeamAbbrMapper(Abbr):\n",
    "    if Abbr == 'ARI':\n",
    "        return 'ARZ'\n",
    "    if Abbr == 'BAL':\n",
    "        return 'BLT'\n",
    "    if Abbr == 'CLE':\n",
    "        return 'CLV'\n",
    "    if Abbr == 'HOU':\n",
    "        return 'HST'\n",
    "    else:\n",
    "        return Abbr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "def OffenseFormationMapper(Formation):\n",
    "    Split = Formation.split(\",\")\n",
    "    Positions = []\n",
    "    Nums = []\n",
    "    \n",
    "    for s in Split:\n",
    "        Position = s.split(\" \")[-1]\n",
    "        Positions.append(Position)\n",
    "        \n",
    "        Num = s.split(\" \")[-2]\n",
    "        Nums.append(Num)\n",
    "\n",
    "    PositionLists = []\n",
    "    for i in range(len(Positions)):\n",
    "        PositionList = list(itertools.repeat(Positions[i], int(Nums[i])))\n",
    "        PositionLists = PositionLists + PositionList\n",
    "\n",
    "    OffenseDic = {'OL' : 0,'QB' : 0,'RB' : 0,'TE' : 0,'WR' : 0}\n",
    "\n",
    "    OffenseDic['OL'] = PositionLists.count('OL')\n",
    "    OffenseDic['QB'] = PositionLists.count('QB')\n",
    "    OffenseDic['RB'] = PositionLists.count('RB')\n",
    "    OffenseDic['TE'] = PositionLists.count('TE')\n",
    "    OffenseDic['WR'] = PositionLists.count('WR')\n",
    "    \n",
    "    return OffenseDic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DefenseFormationMapper(Formation):\n",
    "    Split = Formation.split(\",\")\n",
    "    Positions = []\n",
    "    Nums = []\n",
    "    \n",
    "    for s in Split:\n",
    "        Position = s.split(\" \")[-1]\n",
    "        Positions.append(Position)\n",
    "        \n",
    "        Num = s.split(\" \")[-2]\n",
    "        Nums.append(Num)\n",
    "\n",
    "    PositionLists = []\n",
    "    for i in range(len(Positions)):\n",
    "        PositionList = list(itertools.repeat(Positions[i], int(Nums[i])))\n",
    "        PositionLists = PositionLists + PositionList\n",
    "\n",
    "    DefenseDic = {'DB' : 0, 'DL' : 0, 'LB' : 0, 'OL' : 0}\n",
    "\n",
    "    DefenseDic['DB'] = PositionLists.count('DB')\n",
    "    DefenseDic['DL'] = PositionLists.count('DL')\n",
    "    DefenseDic['LB'] = PositionLists.count('LB')\n",
    "    DefenseDic['OL'] = PositionLists.count('OL')\n",
    "    \n",
    "    return DefenseDic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PreprocessingTrainSet(train):    \n",
    "    #GroupFeatures\n",
    "#     GroupFeatures = ['Yards_OffenseFormation_mean', 'Yards_DefendersInTheBox_mean', 'Yards_Down_mean', 'Yards_PossessionTeam_mean']\n",
    "\n",
    "#     temp = train.groupby('OffenseFormation')['Yards'].agg(['mean']).rename({'mean':'Yards_OffenseFormation_mean'},axis=1)\n",
    "#     train = pd.merge(train,temp,on='OffenseFormation',how='left')\n",
    "\n",
    "#     temp = train.groupby('DefendersInTheBox')['Yards'].agg(['mean']).rename({'mean':'Yards_DefendersInTheBox_mean'},axis=1)\n",
    "#     train = pd.merge(train,temp,on='DefendersInTheBox',how='left')\n",
    "\n",
    "#     temp = train.groupby('Down')['Yards'].agg(['mean']).rename({'mean':'Yards_Down_mean'},axis=1)\n",
    "#     train = pd.merge(train,temp,on='Down',how='left')\n",
    "\n",
    "#     temp = train.groupby('PossessionTeam')['Yards'].agg(['mean']).rename({'mean':'Yards_PossessionTeam_mean'},axis=1)\n",
    "#     train = pd.merge(train,temp,on='PossessionTeam',how='left')\n",
    "\n",
    "#     GroupFeaturesDf = train[['PlayId'] + GroupFeatures].groupby('PlayId').agg('mean')\n",
    "\n",
    "    #Ground & Weather Conditions \n",
    "    ConditionFeatures = ['StadiumType','Turf','GameWeather','Temperature','Humidity','WindSpeed',\n",
    "    'WindDirection', 'Stadium', 'Location']\n",
    "    Drop = ['Stadium','Location']\n",
    "    Drops = Drop\n",
    "\n",
    "    train['StadiumType'] = train['StadiumType'].apply(clean_StadiumType)\n",
    "    train['StadiumType'] = train['StadiumType'].apply(transform_StadiumType)\n",
    "    train['Turf'] = train['Turf'].map(Turf)\n",
    "\n",
    "    #WindSpeed\n",
    "    train['WindSpeed'] = train['WindSpeed'].apply(lambda x: x.lower().replace('mph', '').strip() if not pd.isna(x) else x)\n",
    "    train['WindSpeed'] = train['WindSpeed'].apply(lambda x: (int(x.split('-')[0])+int(x.split('-')[1]))/2 if not pd.isna(x) and '-' in x else x)\n",
    "    train['WindSpeed'] = train['WindSpeed'].apply(lambda x: (int(x.split()[0])+int(x.split()[-1]))/2 if not pd.isna(x) and type(x)!=float and 'gusts up to' in x else x)\n",
    "    train['WindSpeed'] = train['WindSpeed'].apply(str_to_float)\n",
    "\n",
    "    #WindDirection\n",
    "    train['WindDirection'] = train['WindDirection'].apply(clean_WindDirection)\n",
    "    train['WindDirection'] = train['WindDirection'].apply(transform_WindDirection)\n",
    "\n",
    "    #GameWeather\n",
    "    train['GameWeather'] = train['GameWeather'].str.lower()\n",
    "    indoor = \"indoor\"\n",
    "    train['GameWeather'] = train['GameWeather'].apply(lambda x: indoor if not pd.isna(x) and indoor in x else x)\n",
    "    train['GameWeather'] = train['GameWeather'].apply(lambda x: x.replace('coudy', 'cloudy').replace('clouidy', 'cloudy').replace('party', 'partly') if not pd.isna(x) else x)\n",
    "    train['GameWeather'] = train['GameWeather'].apply(lambda x: x.replace('clear and sunny', 'sunny and clear') if not pd.isna(x) else x)\n",
    "    train['GameWeather'] = train['GameWeather'].apply(lambda x: x.replace('skies', '').replace(\"mostly\", \"\").strip() if not pd.isna(x) else x)\n",
    "    train['GameWeather'] = train['GameWeather'].apply(map_weather)\n",
    "\n",
    "    #Drop Location\n",
    "    train = train.drop(columns = Drop)\n",
    "\n",
    "    #Time Features\n",
    "    TimeFeatures = ['TimeHandoff','TimeSnap','Season','Quarter','Week']\n",
    "    Drop = ['TimeHandoff','TimeSnap','GameClock']\n",
    "    Drops = Drops + Drop\n",
    "\n",
    "    #Handle Time Data\n",
    "    train['TimeHandoff'] = train['TimeHandoff'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n",
    "    train['TimeSnap'] = train['TimeSnap'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n",
    "    train['PlayerBirthDate'] = train['PlayerBirthDate'].apply(lambda x: datetime.datetime.strptime(x, \"%m/%d/%Y\"))\n",
    "\n",
    "    #New Features\n",
    "    train['SnaptoHandoff'] = train.apply(lambda row: (row['TimeHandoff'] - row['TimeSnap']).total_seconds(), axis=1)\n",
    "    train['QuarterSecondsLeft'] = train['GameClock'].apply(lambda x: int(x[0:2])*60 + int(x[3:5]))\n",
    "    train['GameSecondsLeft'] = train['Quarter'].map({1:2700, 2:1800, 3:900, 4:0}) + train['QuarterSecondsLeft']\n",
    "    train['GameSecondsPassed'] = 3600 - train['GameSecondsLeft']\n",
    "    train['PlayerAge'] = 2019 - train.PlayerBirthDate.apply(lambda x : x.year)\n",
    "\n",
    "    #For 5th Quarter\n",
    "    train.loc[(train['Quarter'] == 5),'GameSecondsLeft'] = -1\n",
    "    train.loc[(train['Quarter'] == 5),'QuarterSecondsLeft'] = -1\n",
    "    train.loc[(train['Quarter'] == 5),'GameSecondsPassed'] = 3600\n",
    "\n",
    "    #Drop useless features\n",
    "    train = train.drop(columns = Drop)\n",
    "\n",
    "    #Team Features\n",
    "    TeamFeatures = ['Team','HomeTeamAbbr','VisitorTeamAbbr','HomeScoreBeforePlay',\n",
    "    'VisitorScoreBeforePlay','PossessionTeam','FieldPosition','Dis','YardLine','Down','Distance',\n",
    "    'OffenseFormation','OffensePersonnel','DefendersInTheBox','DefensePersonnel']\n",
    "    Drop = ['HomeTeamAbbr','VisitorTeamAbbr','HomeScoreBeforePlay','VisitorScoreBeforePlay',\n",
    "    'PossessionTeam', 'FieldPosition']\n",
    "    Drops = Drops + Drop\n",
    "\n",
    "    #Possession\n",
    "    #To Handle some typos\n",
    "    map_abbr = {'ARI': 'ARZ', 'BAL': 'BLT', 'CLE': 'CLV', 'HOU': 'HST'}\n",
    "\n",
    "    for abb in train['PossessionTeam'].unique():\n",
    "        map_abbr[abb] = abb\n",
    "\n",
    "    train['PossessionTeam'] = train['PossessionTeam'].map(map_abbr)\n",
    "    train['HomeTeamAbbr'] = train['HomeTeamAbbr'].map(map_abbr)\n",
    "    train['VisitorTeamAbbr'] = train['VisitorTeamAbbr'].map(map_abbr)\n",
    "\n",
    "    #New Features\n",
    "    train['OffenseTeamAbbr'] = train['PossessionTeam']\n",
    "    train['DefenseTeamAbbr'] = train.apply(lambda row : row['VisitorTeamAbbr'] if row['OffenseTeamAbbr'] == row['HomeTeamAbbr'] else row['HomeTeamAbbr'], axis = 1)\n",
    "    train['isOffenseHome'] = train['HomeTeamAbbr'] == train['PossessionTeam']\n",
    "    train['isOffenseField'] = train['FieldPosition'] == train['PossessionTeam']\n",
    "    train['OffenseLeadScore'] = train.apply(lambda row : row['HomeScoreBeforePlay'] - row['VisitorScoreBeforePlay'] if row['isOffenseHome'] == 'True' else row['VisitorScoreBeforePlay'] - row['HomeScoreBeforePlay'], axis = 1)\n",
    "    train['OffenseYardLine'] =  train.apply(YardGain, axis = 1)\n",
    "\n",
    "    #Strategies & Formations\n",
    "    FormationFeatures = ['OffensePersonnel','DefendersInTheBox',\n",
    "                         'DefensePersonnel']\n",
    "    Drop = ['OffensePersonnel','DefensePersonnel']\n",
    "    Drops.append(Drop)\n",
    "\n",
    "\n",
    "\n",
    "    #OffensivePersonnel\n",
    "    temp = train[\"OffensePersonnel\"].iloc[np.arange(0, len(train), 22)].apply(lambda x : pd.Series(OffenseFormationMapper(x)))\n",
    "    temp.columns = [\"Offense\" + c for c in temp.columns]\n",
    "    temp[\"PlayId\"] = train[\"PlayId\"].iloc[np.arange(0, len(train), 22)]\n",
    "    train = train.merge(temp, on = 'PlayId')\n",
    "\n",
    "    #DefensivePersonnel\n",
    "    temp = train[\"DefensePersonnel\"].iloc[np.arange(0, len(train), 22)].apply(lambda x : pd.Series(DefenseFormationMapper(x)))\n",
    "    temp.columns = [\"Defense\" + c for c in temp.columns]\n",
    "    temp[\"PlayId\"] = train[\"PlayId\"].iloc[np.arange(0, len(train), 22)]\n",
    "    train = train.merge(temp, on = 'PlayId')\n",
    "\n",
    "    #Drop\n",
    "    train = train.drop(columns = Drop)\n",
    "\n",
    "    #Player Features\n",
    "    PlayerFeatures = ['Team','DisplayName','JerseyNumber','NflIdRusher','PlayerCollegeName',\n",
    "    'NflId','X','Y','S','A','Orientation','Dir','PlayerHeight','PlayerWeight','Position',\n",
    "    'PlayerBirthDate']\n",
    "\n",
    "    Drop = ['Team','DisplayName','JerseyNumber','NflIdRusher','PlayerCollegeName','NflId',\n",
    "    'PlayerBirthDate']\n",
    "    Drops = Drops + Drop\n",
    "\n",
    "    #Height , Weight , BMI\n",
    "    train['PlayerHeight'] = train['PlayerHeight'].apply(lambda x: 12*int(x.split('-')[0])+int(x.split('-')[1]))\n",
    "    train['PlayerBMI'] = 703*(train['PlayerWeight']/(train['PlayerHeight'])**2)\n",
    "\n",
    "    #Position Cleaning\n",
    "\n",
    "    train['Position'] = train.Position.replace('DE','DL')\n",
    "    train['Position'] = train.Position.replace('DT','DL')\n",
    "    train['Position'] = train.Position.replace('NT','DL')\n",
    "\n",
    "    train['Position'] = train.Position.replace('ILB','LB')\n",
    "    train['Position'] = train.Position.replace('MLB','LB')\n",
    "    train['Position'] = train.Position.replace('OLB','LB')\n",
    "\n",
    "    train['Position'] = train.Position.replace('CB','DB')\n",
    "\n",
    "    train['Position'] = train.Position.replace('FS','S')\n",
    "    train['Position'] = train.Position.replace('SS','S')\n",
    "    train['Position'] = train.Position.replace('SAF','S')\n",
    "\n",
    "    train['Position'] = train.Position.replace('HB','RB')\n",
    "\n",
    "    train['Position'] = train.Position.replace('C','OL')\n",
    "    train['Position'] = train.Position.replace('G','OL')\n",
    "    train['Position'] = train.Position.replace('T','OL')\n",
    "    train['Position'] = train.Position.replace('OT','OL')\n",
    "    train['Position'] = train.Position.replace('OG','OL')\n",
    "    train['Position'] = train.Position.replace('OG','OL')\n",
    "\n",
    "    #Position Encoding\n",
    "    train['Position'] = train.Position.replace('DL',-4)\n",
    "    train['Position'] = train.Position.replace('LB',-3)\n",
    "    train['Position'] = train.Position.replace('DB',-2)\n",
    "    train['Position'] = train.Position.replace('S',-1)\n",
    "\n",
    "    train['Position'] = train.Position.replace('RB',6)\n",
    "    train['Position'] = train.Position.replace('WR',5)\n",
    "    train['Position'] = train.Position.replace('FB',4)\n",
    "    train['Position'] = train.Position.replace('QB',3)\n",
    "    train['Position'] = train.Position.replace('OL',2)\n",
    "    train['Position'] = train.Position.replace('TE',1)\n",
    "\n",
    "    #Transform Orientation to Radian\n",
    "    train['Orientation_rad'] = np.mod(train.Orientation, 360) * math.pi/180.0\n",
    "\n",
    "    #Fix shifted orientation \n",
    "    train.loc[train.Season >= 2018, 'Orientation_rad'] = np.mod(train.loc[train.Season >= 2018, 'Orientation'] - 90, 360) * math.pi/180.0\n",
    "\n",
    "    #Overwrite Orientation\n",
    "    train['Orientation'] = train['Orientation_rad']\n",
    "    train.drop(columns = 'Orientation_rad',inplace = True)\n",
    "\n",
    "    #PlayerInfo Dataframe\n",
    "    PlayerInfo = train[['PlayId','DisplayName','NflId','NflIdRusher','X','Y','Position','Team','isOffenseHome','A','S','PlayerAge','PlayerWeight','PlayerHeight','PlayerBMI','Dir','Orientation']]\n",
    "    PlayerInfo.set_index('PlayId',inplace = True)\n",
    "\n",
    "    #Create RusherInfo Dataframe\n",
    "    RusherInfo = train[(train['NflId'] == train['NflIdRusher'])][['PlayId','DisplayName','Position','X','Y','A','S','Dir','Orientation','PlayerAge','PlayerHeight','PlayerWeight','PlayerBMI']].set_index('PlayId')[['DisplayName','Position','X','Y','A','S','Dir','Orientation','PlayerAge','PlayerHeight','PlayerWeight','PlayerBMI']]\n",
    "    RusherInfo.columns = ['RusherName','RusherPosition','X_Rusher','Y_Rusher','A_Rusher','S_Rusher','Dir_Rusher','Orientation_Rusher','PlayerAge_Rusher','PlayerHeight_Rusher','PlayerWeight_Rusher','PlayerBMI_Rusher']\n",
    "\n",
    "    #Add Player's performance\n",
    "    Top10Rusher = ['Christian McCaffrey','Kenyan Drake','Nick Chubb','Dalvin Cook','Ezekiel Elliott',\n",
    "    'Leonard Fournette','Josh Jacobs','Chris Carson','Marlon Mack','Lamar Jackson']\n",
    "    RusherInfo['isTop10Rusher'] = RusherInfo['RusherName'].isin(Top10Rusher)\n",
    "\n",
    "    #Rusher's vertical / horizontal physics\n",
    "    RadianAngle = (90 - RusherInfo['Dir_Rusher']) * np.pi / 180.0\n",
    "    RusherInfo['A_Horizontal_Rusher'] = np.abs(RusherInfo['A_Rusher'] * np.cos(RadianAngle))\n",
    "    RusherInfo['A_Vertical_Rusher'] = np.abs(RusherInfo['A_Rusher'] * np.sin(RadianAngle))\n",
    "\n",
    "    RusherInfo['S_Horizontal_Rusher'] = np.abs(RusherInfo['S_Rusher'] * np.cos(RadianAngle))\n",
    "    RusherInfo['S_Vertical_Rusher'] = np.abs(RusherInfo['S_Rusher'] * np.sin(RadianAngle))\n",
    "\n",
    "    RusherInfo['F_Rusher'] = np.sqrt(RusherInfo['A_Horizontal_Rusher']**2 + RusherInfo['A_Vertical_Rusher']**2) * RusherInfo['PlayerWeight_Rusher']\n",
    "    RusherInfo['KE_Rusher'] = (1/2) *  RusherInfo['PlayerWeight_Rusher'] * (RusherInfo['S_Horizontal_Rusher']**2 + RusherInfo['S_Vertical_Rusher']**2)\n",
    "\n",
    "    #Concat PlayerInfo & RusherInfo\n",
    "    InfoDf = pd.concat([PlayerInfo,RusherInfo],1)\n",
    "\n",
    "    #Create DistanceFromRusher / isOffense\n",
    "    InfoDf['DistanceFromRusher'] = np.sqrt((InfoDf['X_Rusher'] - InfoDf['X'])**2 + (InfoDf['Y_Rusher'] - InfoDf['Y'])**2)\n",
    "    InfoDf['isOffense'] = InfoDf.apply(lambda row : True if ((row['Team'] == 'home') & (row['isOffenseHome'] == True)) | (row['Team'] == 'away') & (row['isOffenseHome'] == False) else False, axis = 1)\n",
    "\n",
    "\n",
    "    #Nearest distance between defensive team & rusher\n",
    "    MinDistance = InfoDf[InfoDf['isOffense']==False][['DistanceFromRusher']].groupby('PlayId').agg(min)\n",
    "    MinDistance.columns = ['NearestDistanceFromRusher']\n",
    "    DistanceDf = pd.concat([InfoDf,MinDistance],1)\n",
    "\n",
    "    #Create DefenderInfo Dataframe\n",
    "    DefensivePosition = [4,-3,-2,-1]\n",
    "    DefenderInfo = DistanceDf[DistanceDf['isOffense'] == False]\n",
    "    NearestDefenderInfo = DefenderInfo[DefenderInfo['DistanceFromRusher'] == DefenderInfo['NearestDistanceFromRusher']]\n",
    "\n",
    "    DistanceDf['A_NearestDefender'] = NearestDefenderInfo['A']\n",
    "    DistanceDf['S_NearestDefender'] = NearestDefenderInfo['S']\n",
    "    DistanceDf['Orientation_NearestDefender'] = NearestDefenderInfo['Orientation']\n",
    "    DistanceDf['Dir_NearestDefender'] = NearestDefenderInfo['Dir']\n",
    "\n",
    "    RadianAngle = (90 - NearestDefenderInfo['Dir']) * np.pi / 180.0\n",
    "    DistanceDf['A_Horizontal_NearestDefender'] = np.abs(DistanceDf['A'] * np.cos(RadianAngle))\n",
    "    DistanceDf['A_Vertical_NearestDefender'] = np.abs(DistanceDf['A'] * np.sin(RadianAngle))\n",
    "\n",
    "    DistanceDf['S_Horizontal_NearestDefender'] = np.abs(DistanceDf['S'] * np.cos(RadianAngle))\n",
    "    DistanceDf['S_Vertical_NearestDefender'] = np.abs(DistanceDf['S'] * np.sin(RadianAngle))\n",
    "\n",
    "    DistanceDf['F_NearestDefender'] = np.sqrt(DistanceDf['A_Horizontal_NearestDefender']**2 + DistanceDf['A_Vertical_NearestDefender']**2) * DistanceDf['PlayerWeight']\n",
    "    DistanceDf['KE_Rusher'] = (1/2) *  DistanceDf['PlayerWeight'] * (DistanceDf['S_Horizontal_NearestDefender']**2 + DistanceDf['S_Vertical_NearestDefender']**2)\n",
    "\n",
    "    PlayerFeatures = ['PlayId','Position','X','Y','S','A','Dis','Orientation','Dir','PlayerHeight',\n",
    "    'PlayerWeight','PlayerAge']\n",
    "\n",
    "    ToBeDropped = ['GameId','Team','NflId','DisplayName','JerseyNumber','YardLine',\n",
    "    'PossessionTeam','FieldPosition','HomeScoreBeforePlay','VisitorScoreBeforePlay',\n",
    "    'RusherName','NflIdRusher','PlayDirection','PlayerBirthDate','PlayerCollegeName',\n",
    "    'HomeTeamAbbr','VisitorTeamAbbr','isRusher','isOffense']\n",
    "\n",
    "    NflDf = pd.concat([train[[f for f in list(train.columns) if f not in list(DistanceDf.columns)]],DistanceDf.reset_index().drop(columns = 'PlayId')], 1)\n",
    "\n",
    "    PlayerDf = NflDf[PlayerFeatures]\n",
    "\n",
    "    count = PlayerDf.groupby(['PlayId']).cumcount() + 1\n",
    "    PlayerDf = PlayerDf.set_index(['PlayId', count]).unstack().sort_index(1, level=1)\n",
    "    PlayerDf = PlayerDf.reset_index()\n",
    "    PlayerFeatures = list(PlayerDf.columns)\n",
    "\n",
    "    feats = []\n",
    "    for i in range(len(PlayerDf.columns)):\n",
    "        feat = ''.join(list(PlayerDf.columns[i][0] + str(PlayerDf.columns[i][1])))\n",
    "        feats.append(feat)\n",
    "    PlayerDf.columns = feats\n",
    "\n",
    "    OneHotFeatures = ['OffenseTeamAbbr','DefenseTeamAbbr','RusherPosition','OffenseFormation']\n",
    "\n",
    "    Booleans = ['isOffenseHome','isTop10Rusher','isOffenseField']\n",
    "    BoolMap = {True : 1, False : 0}\n",
    "\n",
    "    #Create TeamDf\n",
    "    TeamFeatures = [f for f in NflDf.columns if f not in ToBeDropped + PlayerFeatures]\n",
    "\n",
    "    TeamDf = NflDf[TeamFeatures]\n",
    "    TeamDf['PlayId'] = train['PlayId']\n",
    "\n",
    "    #PlayerCode Decoding\n",
    "    TeamDf['RusherPosition'] = TeamDf.RusherPosition.replace(-4,'DL')\n",
    "    TeamDf['RusherPosition'] = TeamDf.RusherPosition.replace(-3,'LB')\n",
    "    TeamDf['RusherPosition'] = TeamDf.RusherPosition.replace(-2,'DB')\n",
    "    TeamDf['RusherPosition'] = TeamDf.RusherPosition.replace(-1,'S')\n",
    "\n",
    "    TeamDf['RusherPosition'] = TeamDf.RusherPosition.replace(6,'RB')\n",
    "    TeamDf['RusherPosition'] = TeamDf.RusherPosition.replace(5,'WR')\n",
    "    TeamDf['RusherPosition'] = TeamDf.RusherPosition.replace(4,'FB')\n",
    "    TeamDf['RusherPosition'] = TeamDf.RusherPosition.replace(3,'QB')\n",
    "    TeamDf['RusherPosition'] = TeamDf.RusherPosition.replace(2,'OL')\n",
    "    TeamDf['RusherPosition'] = TeamDf.RusherPosition.replace(1,'TE')\n",
    "\n",
    "\n",
    "\n",
    "    NumDf = TeamDf[[f for f in TeamDf.columns if f not in Booleans + OneHotFeatures]]\n",
    "    BoolDf = TeamDf[Booleans].stack().map(BoolMap).unstack()\n",
    "\n",
    "    Dummies = TeamDf[OneHotFeatures]\n",
    "    #Fill Nulls\n",
    "    for col in Dummies.columns:\n",
    "        Dummies[col].fillna(Dummies[col].mode()[0],inplace = True)\n",
    "\n",
    "    enc = OneHotEncoder(handle_unknown='ignore')\n",
    "    DummyDf = enc.fit_transform(Dummies)\n",
    "    DummyDf = pd.DataFrame(DummyDf.toarray())\n",
    "    DummyDf.columns = enc.get_feature_names()\n",
    "\n",
    "\n",
    "    TeamDf = pd.concat([NumDf,BoolDf,DummyDf], 1)\n",
    "    TeamDf = TeamDf.groupby(['PlayId']).agg('mean')\n",
    "\n",
    "    Df = pd.concat([PlayerDf,TeamDf.reset_index().drop(columns = 'PlayId')],1)\n",
    "\n",
    "    #Distance From Scrimmage Line\n",
    "    Df['PlayDirection'] = train.groupby('PlayId')[['PlayDirection']].agg(pd.Series.mode).reset_index().drop(columns = 'PlayId')['PlayDirection']\n",
    "    Df['DistanceFromScrimmageLine'] = Df.apply(DistanceFromScrimmageLine, axis = 1)\n",
    "\n",
    "    Df = Df.drop(columns = 'PlayDirection')\n",
    "    Df = Df.drop(columns = 'PlayId')\n",
    "    Df = Df[[f for f in Df.columns if f not in list(PlayerDf.columns)]]\n",
    "    Df.drop(columns = ['X','Y','S','A','Orientation','Dir','PlayerHeight','PlayerWeight','Position','PlayerAge','PlayerBMI'], inplace = True)\n",
    "\n",
    "\n",
    "    #Fill Nulls : Mode\n",
    "    for col in Df.columns:\n",
    "        Df[col].fillna(Df[col].mode()[0],inplace = True)\n",
    "\n",
    "    return Df, enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PreprocessingTestSet(TestDf, enc):\n",
    "    \n",
    "    #GroupFeatures\n",
    "#   GroupFeatures = ['Yards_OffenseFormation_mean', 'Yards_DefendersInTheBox_mean', 'Yards_Down_mean', 'Yards_PossessionTeam_mean']\n",
    "\n",
    "#   temp = TestDf.groupby('OffenseFormation')['Yards'].agg(['mean']).rename({'mean':'Yards_OffenseFormation_mean'},axis=1)\n",
    "#   TestDf = pd.merge(TestDf,temp,on='OffenseFormation',how='left')\n",
    "\n",
    "#   temp = TestDf.groupby('DefendersInTheBox')['Yards'].agg(['mean']).rename({'mean':'Yards_DefendersInTheBox_mean'},axis=1)\n",
    "#   TestDf = pd.merge(TestDf,temp,on='DefendersInTheBox',how='left')\n",
    "\n",
    "#   temp = TestDf.groupby('Down')['Yards'].agg(['mean']).rename({'mean':'Yards_Down_mean'},axis=1)\n",
    "#   TestDf = pd.merge(TestDf,temp,on='Down',how='left')\n",
    "\n",
    "#   temp = TestDf.groupby('PossessionTeam')['Yards'].agg(['mean']).rename({'mean':'Yards_PossessionTeam_mean'},axis=1)\n",
    "#   TestDf = pd.merge(TestDf,temp,on='PossessionTeam',how='left')\n",
    "\n",
    "#   GroupFeaturesDf = TestDf[['PlayId'] + GroupFeatures].groupby('PlayId').agg('mean')\n",
    "    #Ground & Weather Conditions \n",
    "    ConditionFeatures = ['StadiumType','Turf','GameWeather','Temperature','Humidity','WindSpeed',\n",
    "                         'WindDirection', 'Stadium', 'Location']\n",
    "    Drop = ['Stadium','Location']\n",
    "    Drops = Drop\n",
    "\n",
    "    TestDf['StadiumType'] = TestDf['StadiumType'].apply(clean_StadiumType)\n",
    "    TestDf['StadiumType'] = TestDf['StadiumType'].apply(transform_StadiumType)\n",
    "    TestDf['Turf'] = TestDf['Turf'].map(Turf)\n",
    "\n",
    "    #WindSpeed\n",
    "    TestDf['WindSpeed'] = TestDf['WindSpeed'].apply(lambda x: x.lower().replace('mph', '').strip() if not pd.isna(x) else x)\n",
    "    TestDf['WindSpeed'] = TestDf['WindSpeed'].apply(lambda x: (int(x.split('-')[0])+int(x.split('-')[1]))/2 if not pd.isna(x) and '-' in x else x)\n",
    "    TestDf['WindSpeed'] = TestDf['WindSpeed'].apply(lambda x: (int(x.split()[0])+int(x.split()[-1]))/2 if not pd.isna(x) and type(x)!=float and 'gusts up to' in x else x)\n",
    "    TestDf['WindSpeed'] = TestDf['WindSpeed'].apply(str_to_float)\n",
    "\n",
    "    #WindDirection\n",
    "    TestDf['WindDirection'] = TestDf['WindDirection'].apply(clean_WindDirection)\n",
    "    TestDf['WindDirection'] = TestDf['WindDirection'].apply(transform_WindDirection)\n",
    "\n",
    "    #GameWeather\n",
    "    TestDf['GameWeather'] = TestDf['GameWeather'].str.lower()\n",
    "    indoor = \"indoor\"\n",
    "    TestDf['GameWeather'] = TestDf['GameWeather'].apply(lambda x: indoor if not pd.isna(x) and indoor in x else x)\n",
    "    TestDf['GameWeather'] = TestDf['GameWeather'].apply(lambda x: x.replace('coudy', 'cloudy').replace('clouidy', 'cloudy').replace('party', 'partly') if not pd.isna(x) else x)\n",
    "    TestDf['GameWeather'] = TestDf['GameWeather'].apply(lambda x: x.replace('clear and sunny', 'sunny and clear') if not pd.isna(x) else x)\n",
    "    TestDf['GameWeather'] = TestDf['GameWeather'].apply(lambda x: x.replace('skies', '').replace(\"mostly\", \"\").strip() if not pd.isna(x) else x)\n",
    "    TestDf['GameWeather'] = TestDf['GameWeather'].apply(map_weather)\n",
    "\n",
    "    #Drop Location\n",
    "    TestDf = TestDf.drop(columns = Drop)\n",
    "\n",
    "    #Time Features\n",
    "    TimeFeatures = ['TimeHandoff','TimeSnap','Season','Quarter','Week']\n",
    "    Drop = ['TimeHandoff','TimeSnap','GameClock']\n",
    "    Drops = Drops + Drop\n",
    "\n",
    "    #Handle Time Data\n",
    "    TestDf['TimeHandoff'] = TestDf['TimeHandoff'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n",
    "    TestDf['TimeSnap'] = TestDf['TimeSnap'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n",
    "    TestDf['PlayerBirthDate'] = TestDf['PlayerBirthDate'].apply(lambda x: datetime.datetime.strptime(x, \"%m/%d/%Y\"))\n",
    "\n",
    "    #New Features\n",
    "    TestDf['SnaptoHandoff'] = TestDf.apply(lambda row: (row['TimeHandoff'] - row['TimeSnap']).total_seconds(), axis=1)\n",
    "    TestDf['QuarterSecondsLeft'] = TestDf['GameClock'].apply(lambda x: int(x[0:2])*60 + int(x[3:5]))\n",
    "    TestDf['GameSecondsLeft'] = TestDf['Quarter'].map({1:2700, 2:1800, 3:900, 4:0}) + TestDf['QuarterSecondsLeft']\n",
    "    TestDf['GameSecondsPassed'] = 3600 - TestDf['GameSecondsLeft']\n",
    "    TestDf['PlayerAge'] = 2019 - TestDf.PlayerBirthDate.apply(lambda x : x.year)\n",
    "\n",
    "    #For 5th Quarter\n",
    "    TestDf.loc[(TestDf['Quarter'] == 5),'GameSecondsLeft'] = -1\n",
    "    TestDf.loc[(TestDf['Quarter'] == 5),'QuarterSecondsLeft'] = -1\n",
    "    TestDf.loc[(TestDf['Quarter'] == 5),'GameSecondsPassed'] = 3600\n",
    "\n",
    "    #Drop useless features\n",
    "    TestDf = TestDf.drop(columns = Drop)\n",
    "\n",
    "    #Team Features\n",
    "    TeamFeatures = ['Team','HomeTeamAbbr','VisitorTeamAbbr','HomeScoreBeforePlay',\n",
    "    'VisitorScoreBeforePlay','PossessionTeam','FieldPosition','Dis','YardLine','Down','Distance',\n",
    "    'OffenseFormation','OffensePersonnel','DefendersInTheBox','DefensePersonnel']\n",
    "    Drop = ['HomeTeamAbbr','VisitorTeamAbbr','HomeScoreBeforePlay','VisitorScoreBeforePlay',\n",
    "    'PossessionTeam', 'FieldPosition']\n",
    "    Drops = Drops + Drop\n",
    "\n",
    "    TestDf['PossessionTeam'] = TestDf['PossessionTeam'].apply(TeamAbbrMapper)\n",
    "    TestDf['HomeTeamAbbr'] = TestDf['HomeTeamAbbr'].apply(TeamAbbrMapper)\n",
    "    TestDf['VisitorTeamAbbr'] = TestDf['VisitorTeamAbbr'].apply(TeamAbbrMapper)\n",
    "\n",
    "    #New Features\n",
    "    TestDf['OffenseTeamAbbr'] = TestDf['PossessionTeam']\n",
    "    TestDf['DefenseTeamAbbr'] = TestDf.apply(lambda row : row['VisitorTeamAbbr'] if row['OffenseTeamAbbr'] == row['HomeTeamAbbr'] else row['HomeTeamAbbr'], axis = 1)\n",
    "    TestDf['isOffenseHome'] = TestDf['HomeTeamAbbr'] == TestDf['PossessionTeam']\n",
    "    TestDf['isOffenseField'] = TestDf['FieldPosition'] == TestDf['PossessionTeam']\n",
    "    TestDf['OffenseLeadScore'] = TestDf.apply(lambda row : row['HomeScoreBeforePlay'] - row['VisitorScoreBeforePlay'] if row['isOffenseHome'] == 'True' else row['VisitorScoreBeforePlay'] - row['HomeScoreBeforePlay'], axis = 1)\n",
    "    TestDf['OffenseYardLine'] =  TestDf.apply(YardGain, axis = 1)\n",
    "\n",
    "    #Strategies & Formations\n",
    "    FormationFeatures = ['OffensePersonnel','DefendersInTheBox',\n",
    "                         'DefensePersonnel']\n",
    "    Drop = ['OffensePersonnel','DefensePersonnel']\n",
    "    Drops.append(Drop)\n",
    "\n",
    "\n",
    "    #OffensivePersonnel\n",
    "    temp = TestDf[\"OffensePersonnel\"].iloc[np.arange(0, len(TestDf), 22)].apply(lambda x : pd.Series(OffenseFormationMapper(x)))\n",
    "    temp.columns = [\"Offense\" + c for c in temp.columns]\n",
    "    temp[\"PlayId\"] = TestDf[\"PlayId\"].iloc[np.arange(0, len(TestDf), 22)]\n",
    "    TestDf = TestDf.merge(temp, on = \"PlayId\")\n",
    "\n",
    "    #DefensivePersonnel\n",
    "    temp = TestDf[\"DefensePersonnel\"].iloc[np.arange(0, len(TestDf), 22)].apply(lambda x : pd.Series(DefenseFormationMapper(x)))\n",
    "    temp.columns = [\"Defense\" + c for c in temp.columns]\n",
    "    temp[\"PlayId\"] = TestDf[\"PlayId\"].iloc[np.arange(0, len(TestDf), 22)]\n",
    "    TestDf = TestDf.merge(temp, on = \"PlayId\")\n",
    "\n",
    "    #Drop\n",
    "    TestDf = TestDf.drop(columns = Drop)\n",
    "\n",
    "    #Player Features\n",
    "    PlayerFeatures = ['Team','DisplayName','JerseyNumber','NflIdRusher','PlayerCollegeName',\n",
    "    'NflId','X','Y','S','A','Orientation','Dir','PlayerHeight','PlayerWeight','Position',\n",
    "    'PlayerBirthDate']\n",
    "\n",
    "    Drop = ['Team','DisplayName','JerseyNumber','NflIdRusher','PlayerCollegeName','NflId',\n",
    "    'PlayerBirthDate']\n",
    "    Drops = Drops + Drop\n",
    "\n",
    "    #Height , Weight , BMI\n",
    "    TestDf['PlayerHeight'] = TestDf['PlayerHeight'].apply(lambda x: 12*int(x.split('-')[0])+int(x.split('-')[1]))\n",
    "    TestDf['PlayerBMI'] = 703*(TestDf['PlayerWeight']/(TestDf['PlayerHeight'])**2)\n",
    "\n",
    "    #Position Cleaning\n",
    "\n",
    "    TestDf['Position'] = TestDf.Position.replace('DE','DL')\n",
    "    TestDf['Position'] = TestDf.Position.replace('DT','DL')\n",
    "    TestDf['Position'] = TestDf.Position.replace('NT','DL')\n",
    "\n",
    "    TestDf['Position'] = TestDf.Position.replace('ILB','LB')\n",
    "    TestDf['Position'] = TestDf.Position.replace('MLB','LB')\n",
    "    TestDf['Position'] = TestDf.Position.replace('OLB','LB')\n",
    "\n",
    "    TestDf['Position'] = TestDf.Position.replace('CB','DB')\n",
    "\n",
    "    TestDf['Position'] = TestDf.Position.replace('FS','S')\n",
    "    TestDf['Position'] = TestDf.Position.replace('SS','S')\n",
    "    TestDf['Position'] = TestDf.Position.replace('SAF','S')\n",
    "\n",
    "    TestDf['Position'] = TestDf.Position.replace('HB','RB')\n",
    "\n",
    "    TestDf['Position'] = TestDf.Position.replace('C','OL')\n",
    "    TestDf['Position'] = TestDf.Position.replace('G','OL')\n",
    "    TestDf['Position'] = TestDf.Position.replace('T','OL')\n",
    "    TestDf['Position'] = TestDf.Position.replace('OT','OL')\n",
    "    TestDf['Position'] = TestDf.Position.replace('OG','OL')\n",
    "    TestDf['Position'] = TestDf.Position.replace('OG','OL')\n",
    "\n",
    "    #Position Encoding\n",
    "    TestDf['Position'] = TestDf.Position.replace('DL',-4)\n",
    "    TestDf['Position'] = TestDf.Position.replace('LB',-3)\n",
    "    TestDf['Position'] = TestDf.Position.replace('DB',-2)\n",
    "    TestDf['Position'] = TestDf.Position.replace('S',-1)\n",
    "\n",
    "    TestDf['Position'] = TestDf.Position.replace('RB',6)\n",
    "    TestDf['Position'] = TestDf.Position.replace('WR',5)\n",
    "    TestDf['Position'] = TestDf.Position.replace('FB',4)\n",
    "    TestDf['Position'] = TestDf.Position.replace('QB',3)\n",
    "    TestDf['Position'] = TestDf.Position.replace('OL',2)\n",
    "    TestDf['Position'] = TestDf.Position.replace('TE',1)\n",
    "    \n",
    "    #Transform Orientation to Radian\n",
    "    TestDf['Orientation_rad'] = np.mod(TestDf.Orientation, 360) * math.pi/180.0\n",
    "    \n",
    "    #Fix shifted orientation \n",
    "    TestDf.loc[TestDf.Season >= 2018, 'Orientation_rad'] = np.mod(TestDf.loc[TestDf.Season >= 2018, 'Orientation'] - 90, 360) * math.pi/180.0\n",
    "    \n",
    "    #Overwrite Orientation\n",
    "    TestDf['Orientation'] = TestDf['Orientation_rad']\n",
    "    TestDf.drop(columns = 'Orientation_rad',inplace = True)\n",
    "    \n",
    "\n",
    "    #PlayerInfo Dataframe\n",
    "    PlayerInfo = TestDf[['PlayId','DisplayName','NflId','NflIdRusher','X','Y','Position','Team','isOffenseHome','A','S','PlayerAge','PlayerWeight','PlayerHeight','PlayerBMI','Dir','Orientation']]\n",
    "    PlayerInfo.set_index('PlayId',inplace = True)\n",
    "\n",
    "    #Create RusherInfo Dataframe\n",
    "    RusherInfo = TestDf[(TestDf['NflId'] == TestDf['NflIdRusher'])][['PlayId','DisplayName','Position','X','Y','A','S','Dir','Orientation','PlayerAge','PlayerHeight','PlayerWeight','PlayerBMI']].set_index('PlayId')[['DisplayName','Position','X','Y','A','S','Dir','Orientation','PlayerAge','PlayerHeight','PlayerWeight','PlayerBMI']]\n",
    "    RusherInfo.columns = ['RusherName','RusherPosition','X_Rusher','Y_Rusher','A_Rusher','S_Rusher','Dir_Rusher','Orientation_Rusher','PlayerAge_Rusher','PlayerHeight_Rusher','PlayerWeight_Rusher','PlayerBMI_Rusher']\n",
    "\n",
    "    #Add Player's performance\n",
    "    Top10Rusher = ['Christian McCaffrey','Kenyan Drake','Nick Chubb','Dalvin Cook','Ezekiel Elliott',\n",
    "    'Leonard Fournette','Josh Jacobs','Chris Carson','Marlon Mack','Lamar Jackson']\n",
    "\n",
    "    RusherInfo['isTop10Rusher'] = RusherInfo['RusherName'].isin(Top10Rusher)\n",
    "    \n",
    "    #Rusher's vertical / horizontal physics\n",
    "    RadianAngle = (90 - RusherInfo['Dir_Rusher']) * np.pi / 180.0\n",
    "    RusherInfo['A_Horizontal_Rusher'] = np.abs(RusherInfo['A_Rusher'] * np.cos(RadianAngle))\n",
    "    RusherInfo['A_Vertical_Rusher'] = np.abs(RusherInfo['A_Rusher'] * np.sin(RadianAngle))\n",
    "\n",
    "    RusherInfo['S_Horizontal_Rusher'] = np.abs(RusherInfo['S_Rusher'] * np.cos(RadianAngle))\n",
    "    RusherInfo['S_Vertical_Rusher'] = np.abs(RusherInfo['S_Rusher'] * np.sin(RadianAngle))\n",
    "\n",
    "    RusherInfo['F_Rusher'] = np.sqrt(RusherInfo['A_Horizontal_Rusher']**2 + RusherInfo['A_Vertical_Rusher']**2) * RusherInfo['PlayerWeight_Rusher']\n",
    "    RusherInfo['KE_Rusher'] = (1/2) *  RusherInfo['PlayerWeight_Rusher'] * (RusherInfo['S_Horizontal_Rusher']**2 + RusherInfo['S_Vertical_Rusher']**2)\n",
    "\n",
    "    #Concat PlayerInfo & RusherInfo\n",
    "    InfoDf = pd.concat([PlayerInfo,RusherInfo],1)\n",
    "\n",
    "    #Create DistanceFromRusher / isOffense\n",
    "    InfoDf['DistanceFromRusher'] = np.sqrt((InfoDf['X_Rusher'] - InfoDf['X'])**2 + (InfoDf['Y_Rusher'] - InfoDf['Y'])**2)\n",
    "    InfoDf['isOffense'] = InfoDf.apply(lambda row : True if ((row['Team'] == 'home') & (row['isOffenseHome'] == True)) | (row['Team'] == 'away') & (row['isOffenseHome'] == False) else False, axis = 1)\n",
    "\n",
    "\n",
    "    #Nearest distance between defensive team & rusher\n",
    "    MinDistance = InfoDf[InfoDf['isOffense']==False][['DistanceFromRusher']].groupby('PlayId').agg(min)\n",
    "    MinDistance.columns = ['NearestDistanceFromRusher']\n",
    "    DistanceDf = pd.concat([InfoDf,MinDistance],1)\n",
    "\n",
    "    #Create DefenderInfo Dataframe\n",
    "    DefensivePosition = [4,-3,-2,-1]\n",
    "    DefenderInfo = DistanceDf[DistanceDf['isOffense'] == False]\n",
    "    NearestDefenderInfo = DefenderInfo[DefenderInfo['DistanceFromRusher'] == DefenderInfo['NearestDistanceFromRusher']]\n",
    "\n",
    "    DistanceDf['A_NearestDefender'] = NearestDefenderInfo['A']\n",
    "    DistanceDf['S_NearestDefender'] = NearestDefenderInfo['S']\n",
    "    DistanceDf['Orientation_NearestDefender'] = NearestDefenderInfo['Orientation']\n",
    "    DistanceDf['Dir_NearestDefender'] = NearestDefenderInfo['Dir']\n",
    "    \n",
    "    RadianAngle = (90 - NearestDefenderInfo['Dir']) * np.pi / 180.0\n",
    "    DistanceDf['A_Horizontal_NearestDefender'] = np.abs(DistanceDf['A'] * np.cos(RadianAngle))\n",
    "    DistanceDf['A_Vertical_NearestDefender'] = np.abs(DistanceDf['A'] * np.sin(RadianAngle))\n",
    "\n",
    "    DistanceDf['S_Horizontal_NearestDefender'] = np.abs(DistanceDf['S'] * np.cos(RadianAngle))\n",
    "    DistanceDf['S_Vertical_NearestDefender'] = np.abs(DistanceDf['S'] * np.sin(RadianAngle))\n",
    "\n",
    "    DistanceDf['F_NearestDefender'] = np.sqrt(DistanceDf['A_Horizontal_NearestDefender']**2 + DistanceDf['A_Vertical_NearestDefender']**2) * DistanceDf['PlayerWeight']\n",
    "    DistanceDf['KE_Rusher'] = (1/2) *  DistanceDf['PlayerWeight'] * (DistanceDf['S_Horizontal_NearestDefender']**2 + DistanceDf['S_Vertical_NearestDefender']**2)\n",
    "\n",
    "    PlayerFeatures = ['PlayId','Position','X','Y','S','A','Dis','Orientation','Dir','PlayerHeight',\n",
    "    'PlayerWeight','PlayerAge']\n",
    "\n",
    "    ToBeDropped = ['GameId','Team','NflId','DisplayName','JerseyNumber','YardLine',\n",
    "    'PossessionTeam','FieldPosition','HomeScoreBeforePlay','VisitorScoreBeforePlay',\n",
    "    'RusherName','NflIdRusher','PlayDirection','PlayerBirthDate','PlayerCollegeName',\n",
    "    'HomeTeamAbbr','VisitorTeamAbbr','isRusher','isOffense']\n",
    "\n",
    "    NflDf = pd.concat([TestDf[[f for f in list(TestDf.columns) if f not in list(DistanceDf.columns)]],DistanceDf.reset_index().drop(columns = 'PlayId')], 1)\n",
    "\n",
    "    PlayerDf = NflDf[PlayerFeatures]\n",
    "\n",
    "    count = PlayerDf.groupby(['PlayId']).cumcount() + 1\n",
    "    PlayerDf = PlayerDf.set_index(['PlayId', count]).unstack().sort_index(1, level=1)\n",
    "    PlayerDf = PlayerDf.reset_index()\n",
    "\n",
    "    feats = []\n",
    "    for i in range(len(PlayerDf.columns)):\n",
    "        feat = ''.join(list(PlayerDf.columns[i][0] + str(PlayerDf.columns[i][1])))\n",
    "        feats.append(feat)\n",
    "    PlayerDf.columns = feats\n",
    "\n",
    "    OneHotFeatures = ['OffenseTeamAbbr','DefenseTeamAbbr','RusherPosition','OffenseFormation']\n",
    "\n",
    "    Booleans = ['isOffenseHome','isTop10Rusher','isOffenseField']\n",
    "    BoolMap = {True : 1, False : 0}\n",
    "\n",
    "    #Create TeamDf\n",
    "    TeamFeatures = [f for f in NflDf.columns if f not in ToBeDropped + PlayerFeatures]\n",
    "\n",
    "    TeamDf = NflDf[TeamFeatures]\n",
    "    TeamDf['PlayId'] = TestDf['PlayId']\n",
    "\n",
    "    #PlayerCode Decoding\n",
    "    TeamDf['RusherPosition'] = TeamDf.RusherPosition.replace(-4,'DL')\n",
    "    TeamDf['RusherPosition'] = TeamDf.RusherPosition.replace(-3,'LB')\n",
    "    TeamDf['RusherPosition'] = TeamDf.RusherPosition.replace(-2,'DB')\n",
    "    TeamDf['RusherPosition'] = TeamDf.RusherPosition.replace(-1,'S')\n",
    "\n",
    "    TeamDf['RusherPosition'] = TeamDf.RusherPosition.replace(6,'RB')\n",
    "    TeamDf['RusherPosition'] = TeamDf.RusherPosition.replace(5,'WR')\n",
    "    TeamDf['RusherPosition'] = TeamDf.RusherPosition.replace(4,'FB')\n",
    "    TeamDf['RusherPosition'] = TeamDf.RusherPosition.replace(3,'QB')\n",
    "    TeamDf['RusherPosition'] = TeamDf.RusherPosition.replace(2,'OL')\n",
    "    TeamDf['RusherPosition'] = TeamDf.RusherPosition.replace(1,'TE')\n",
    "\n",
    "\n",
    "\n",
    "    NumDf = TeamDf[[f for f in TeamDf.columns if f not in Booleans + OneHotFeatures]]\n",
    "    BoolDf = TeamDf[Booleans].stack().map(BoolMap).unstack()\n",
    "\n",
    "    Dummies = TeamDf[OneHotFeatures]\n",
    "    #Fill Nulls\n",
    "    for col in Dummies.columns:\n",
    "        Dummies[col].fillna(Dummies[col].mode()[0],inplace = True)\n",
    "\n",
    "    DummyDf = enc.transform(Dummies)\n",
    "    DummyDf = pd.DataFrame(DummyDf.toarray())\n",
    "    DummyDf.columns = enc.get_feature_names()\n",
    "\n",
    "\n",
    "    TeamDf = pd.concat([NumDf,BoolDf,DummyDf], 1)\n",
    "\n",
    "    TeamDf = TeamDf.groupby(['PlayId']).agg('mean')\n",
    "    Df = pd.concat([PlayerDf,TeamDf.reset_index().drop(columns = 'PlayId')],1)\n",
    "\n",
    "    #Distance From Scrimmage Line\n",
    "    Df['PlayDirection'] = TestDf.groupby('PlayId')[['PlayDirection']].agg(pd.Series.mode).reset_index().drop(columns = 'PlayId')['PlayDirection']\n",
    "    Df['DistanceFromScrimmageLine'] = Df.apply(DistanceFromScrimmageLine, axis = 1)\n",
    "\n",
    "    Df = Df.drop(columns = 'PlayDirection')\n",
    "    Df = Df.drop(columns = 'PlayId')\n",
    "    #Df = Df[[f for f in Df.columns if f not in list(PlayerDf.columns)]]\n",
    "    #Df.drop(columns = ['X','Y','S','A','Orientation','Dir','PlayerHeight','PlayerWeight','Position','PlayerAge','PlayerBMI'], inplace = True)\n",
    "\n",
    "\n",
    "    #Fill Nulls : Mode\n",
    "    for col in Df.columns:\n",
    "        idx = 0\n",
    "        Mode = pd.DataFrame(Df[col].value_counts(dropna = False)).index[idx]\n",
    "        while True:\n",
    "            if np.isnan(Mode) == False:\n",
    "                Df[col].fillna(Mode, inplace = True)\n",
    "                break\n",
    "            else:\n",
    "                Df[col].fillna(-1, inplace = True)\n",
    "                break\n",
    "    \n",
    "    return Df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Radam\n",
    "import keras.optimizers\n",
    "__all__ = ['RAdam']\n",
    "class RAdam(keras.optimizers.Optimizer):\n",
    "    \"\"\"RAdam optimizer.\n",
    "    # Arguments\n",
    "        learning_rate: float >= 0. Learning rate.\n",
    "        beta_1: float, 0 < beta < 1. Generally close to 1.\n",
    "        beta_2: float, 0 < beta < 1. Generally close to 1.\n",
    "        epsilon: float >= 0. Fuzz factor. If `None`, defaults to `K.epsilon()`.\n",
    "        decay: float >= 0. Learning rate decay over each update.\n",
    "        weight_decay: float >= 0. Weight decay for each param.\n",
    "        amsgrad: boolean. Whether to apply the AMSGrad variant of this\n",
    "            algorithm from the paper \"On the Convergence of Adam and\n",
    "            Beyond\".\n",
    "        total_steps: int >= 0. Total number of training steps. Enable warmup by setting a positive value.\n",
    "        warmup_proportion: 0 < warmup_proportion < 1. The proportion of increasing steps.\n",
    "        min_lr: float >= 0. Minimum learning rate after warmup.\n",
    "    # References\n",
    "        - [Adam - A Method for Stochastic Optimization](https://arxiv.org/abs/1412.6980v8)\n",
    "        - [On the Convergence of Adam and Beyond](https://openreview.net/forum?id=ryQu7f-RZ)\n",
    "        - [On The Variance Of The Adaptive Learning Rate And Beyond](https://arxiv.org/pdf/1908.03265v1.pdf)\n",
    "    \"\"\"\n",
    "    def __init__(self, learning_rate=0.001, beta_1=0.9, beta_2=0.999,\n",
    "                 epsilon=None, decay=0., weight_decay=0., amsgrad=False,\n",
    "                 total_steps=0, warmup_proportion=0.1, min_lr=0., **kwargs):\n",
    "        learning_rate = kwargs.pop('lr', learning_rate)\n",
    "        super(RAdam, self).__init__(**kwargs)\n",
    "        with K.name_scope(self.__class__.__name__):\n",
    "            self.iterations = K.variable(0, dtype='int64', name='iterations')\n",
    "            self.learning_rate = K.variable(learning_rate, name='learning_rate')\n",
    "            self.beta_1 = K.variable(beta_1, name='beta_1')\n",
    "            self.beta_2 = K.variable(beta_2, name='beta_2')\n",
    "            self.decay = K.variable(decay, name='decay')\n",
    "            self.weight_decay = K.variable(weight_decay, name='weight_decay')\n",
    "            self.total_steps = K.variable(total_steps, name='total_steps')\n",
    "            self.warmup_proportion = K.variable(warmup_proportion, name='warmup_proportion')\n",
    "            self.min_lr = K.variable(min_lr, name='min_lr')\n",
    "        if epsilon is None:\n",
    "            epsilon = K.epsilon()\n",
    "        self.epsilon = epsilon\n",
    "        self.initial_decay = decay\n",
    "        self.initial_weight_decay = weight_decay\n",
    "        self.initial_total_steps = total_steps\n",
    "        self.amsgrad = amsgrad\n",
    "\n",
    "    def get_updates(self, loss, params):\n",
    "        grads = self.get_gradients(loss, params)\n",
    "        self.updates = [K.update_add(self.iterations, 1)]\n",
    "\n",
    "        lr = self.lr\n",
    "\n",
    "        if self.initial_decay > 0:\n",
    "            lr = lr * (1. / (1. + self.decay * K.cast(self.iterations, K.dtype(self.decay))))\n",
    "\n",
    "        t = K.cast(self.iterations, K.floatx()) + 1\n",
    "\n",
    "        if self.initial_total_steps > 0:\n",
    "            warmup_steps = self.total_steps * self.warmup_proportion\n",
    "            decay_steps = K.maximum(self.total_steps - warmup_steps, 1)\n",
    "            decay_rate = (self.min_lr - lr) / decay_steps\n",
    "            lr = K.switch(\n",
    "                t <= warmup_steps,\n",
    "                lr * (t / warmup_steps),\n",
    "                lr + decay_rate * K.minimum(t - warmup_steps, decay_steps),\n",
    "            )\n",
    "\n",
    "        ms = [K.zeros(K.int_shape(p), dtype=K.dtype(p), name='m_' + str(i)) for (i, p) in enumerate(params)]\n",
    "        vs = [K.zeros(K.int_shape(p), dtype=K.dtype(p), name='v_' + str(i)) for (i, p) in enumerate(params)]\n",
    "\n",
    "        if self.amsgrad:\n",
    "            vhats = [K.zeros(K.int_shape(p), dtype=K.dtype(p), name='vhat_' + str(i)) for (i, p) in enumerate(params)]\n",
    "        else:\n",
    "            vhats = [K.zeros(1, name='vhat_' + str(i)) for i in range(len(params))]\n",
    "\n",
    "        self.weights = [self.iterations] + ms + vs + vhats\n",
    "\n",
    "        beta_1_t = K.pow(self.beta_1, t)\n",
    "        beta_2_t = K.pow(self.beta_2, t)\n",
    "\n",
    "        sma_inf = 2.0 / (1.0 - self.beta_2) - 1.0\n",
    "        sma_t = sma_inf - 2.0 * t * beta_2_t / (1.0 - beta_2_t)\n",
    "\n",
    "        for p, g, m, v, vhat in zip(params, grads, ms, vs, vhats):\n",
    "            m_t = (self.beta_1 * m) + (1. - self.beta_1) * g\n",
    "            v_t = (self.beta_2 * v) + (1. - self.beta_2) * K.square(g)\n",
    "\n",
    "            m_corr_t = m_t / (1.0 - beta_1_t)\n",
    "            if self.amsgrad:\n",
    "                vhat_t = K.maximum(vhat, v_t)\n",
    "                v_corr_t = K.sqrt(vhat_t / (1.0 - beta_2_t))\n",
    "                self.updates.append(K.update(vhat, vhat_t))\n",
    "            else:\n",
    "                v_corr_t = K.sqrt(v_t / (1.0 - beta_2_t))\n",
    "\n",
    "            r_t = K.sqrt((sma_t - 4.0) / (sma_inf - 4.0) *\n",
    "                         (sma_t - 2.0) / (sma_inf - 2.0) *\n",
    "                         sma_inf / sma_t)\n",
    "\n",
    "            p_t = K.switch(sma_t >= 5, r_t * m_corr_t / (v_corr_t + self.epsilon), m_corr_t)\n",
    "\n",
    "            if self.initial_weight_decay > 0:\n",
    "                p_t += self.weight_decay * p\n",
    "\n",
    "            p_t = p - lr * p_t\n",
    "\n",
    "            self.updates.append(K.update(m, m_t))\n",
    "            self.updates.append(K.update(v, v_t))\n",
    "            new_p = p_t\n",
    "\n",
    "            # Apply constraints.\n",
    "            if getattr(p, 'constraint', None) is not None:\n",
    "                new_p = p.constraint(new_p)\n",
    "\n",
    "            self.updates.append(K.update(p, new_p))\n",
    "        return self.updates\n",
    "\n",
    "    @property\n",
    "    def lr(self):\n",
    "        return self.learning_rate\n",
    "\n",
    "    @lr.setter\n",
    "    def lr(self, learning_rate):\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'learning_rate': float(K.get_value(self.learning_rate)),\n",
    "            'beta_1': float(K.get_value(self.beta_1)),\n",
    "            'beta_2': float(K.get_value(self.beta_2)),\n",
    "            'decay': float(K.get_value(self.decay)),\n",
    "            'weight_decay': float(K.get_value(self.weight_decay)),\n",
    "            'epsilon': self.epsilon,\n",
    "            'amsgrad': self.amsgrad,\n",
    "            'total_steps': float(K.get_value(self.total_steps)),\n",
    "            'warmup_proportion': float(K.get_value(self.warmup_proportion)),\n",
    "            'min_lr': float(K.get_value(self.min_lr)),\n",
    "        }\n",
    "        base_config = super(RAdam, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CRPS \n",
    "class CRPSCallBack(Callback):\n",
    "    \n",
    "    def __init__(self,validation, predict_batch_size=20, include_on_batch=False):\n",
    "        super(CRPSCallBack, self).__init__()\n",
    "        self.validation = validation\n",
    "        self.predict_batch_size = predict_batch_size\n",
    "        self.include_on_batch = include_on_batch\n",
    "        \n",
    "        print('validation shape',len(self.validation))\n",
    "\n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        pass\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        if not ('CRPS_Score_Val' in self.params['metrics']):\n",
    "            self.params['metrics'].append('CRPS_Score_Val')\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        if (self.include_on_batch):\n",
    "            logs['CRPS_Score_Val'] = float('-inf')\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        logs['CRPS_Score_Val'] = float('-inf')\n",
    "            \n",
    "        if (self.validation):\n",
    "            X_valid, y_valid = self.validation[0], self.validation[1]\n",
    "            y_pred = self.model.predict(X_valid)\n",
    "            y_true = np.clip(np.cumsum(y_valid, axis=1), 0, 1)\n",
    "            y_pred = np.clip(np.cumsum(y_pred, axis=1), 0, 1)\n",
    "            Val_Score = ((y_true - y_pred) ** 2).sum(axis=1).sum(axis=0) / (199 * X_valid.shape[0])\n",
    "            Val_Score = np.round(Val_Score, 6)\n",
    "            logs['CRPS_Score_Val'] = Val_Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BuildModel(x_tr,y_tr,x_val,y_val):\n",
    "    inp = Input(shape = (x_tr.shape[1],))\n",
    "    x = Dense(1024, input_dim=X.shape[1], activation='relu')(inp)\n",
    "    x = Dropout(0.7)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.7)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.7)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    out = Dense(199, activation='softmax')(x)\n",
    "    model = Model(inp,out)\n",
    "    Radam = RAdam()\n",
    "    Adam = optimizers.Adam()\n",
    "    model.compile(optimizer=Adam, loss='categorical_crossentropy', metrics=[])\n",
    "    \n",
    "    #add lookahead\n",
    "#     lookahead = Lookahead(k=5, alpha=0.5) # Initialize Lookahead\n",
    "#     lookahead.inject(model) # add into model\n",
    "\n",
    "    \n",
    "    es = EarlyStopping(monitor='CRPS_Score_Val', mode='min',restore_best_weights=True,\n",
    "                       verbose=1,patience=10)\n",
    "\n",
    "    #mc = ModelCheckpoint('best_model.h5',monitor='CRPS_score_val',mode='min',\n",
    "                        #save_best_only=True, verbose=1, save_weights_only=True)\n",
    "    \n",
    "    bsz = 1024\n",
    "    steps = x_tr.shape[0]/bsz\n",
    "    lr = 1e-05\n",
    "\n",
    "    model.fit(x_tr, y_tr,callbacks=[CRPSCallBack(validation = (x_val,y_val)),es], epochs=100, batch_size=bsz,verbose=1)\n",
    "    #model.load_weights(\"best_model.h5\")\n",
    "    \n",
    "    y_pred = model.predict(x_val)\n",
    "    y_valid = y_val\n",
    "    y_true = np.clip(np.cumsum(y_valid, axis=1), 0, 1)\n",
    "    y_pred = np.clip(np.cumsum(y_pred, axis=1), 0, 1)\n",
    "    val_s = ((y_true - y_pred) ** 2).sum(axis=1).sum(axis=0) / (199 * x_val.shape[0])\n",
    "    crps = np.round(val_s, 6)\n",
    "\n",
    "    return model,crps\n",
    "\n",
    "def predict(x_te):\n",
    "    model_num = len(models)\n",
    "    for k,m in enumerate(models):\n",
    "        if k==0:\n",
    "            y_pred = m.predict(x_te,batch_size=1024)\n",
    "        else:\n",
    "            y_pred += m.predict(x_te,batch_size=1024)\n",
    "            \n",
    "    y_pred = y_pred / model_num\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "TrainSet, enc = PreprocessingTrainSet(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#Training Session\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import time\n",
    "\n",
    "TrainSet, enc = PreprocessingTrainSet(train)\n",
    "\n",
    "#Split train / val set\n",
    "X = TrainSet.copy()\n",
    "X.drop(['Yards'], axis=1, inplace=True)\n",
    "\n",
    "yards = TrainSet.Yards\n",
    "y = np.zeros((yards.shape[0], 199))\n",
    "for idx, target in enumerate(list(yards.astype(int))):\n",
    "    y[idx][99 + target] = 1\n",
    "\n",
    "#Scaling\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "#Data Split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.15, random_state=12345)\n",
    "\n",
    "losses = []\n",
    "models = []\n",
    "crps_csv = []\n",
    "\n",
    "s_time = time.time()\n",
    "yards = TrainSet.Yards\n",
    "\n",
    "for k in range(2):\n",
    "    kfold = KFold(5, random_state = 42 + k, shuffle = True)\n",
    "    for k_fold, (tr_inds, val_inds) in enumerate(kfold.split(yards)):\n",
    "        print(\"-----------\")\n",
    "        print(\"-----------\")\n",
    "        tr_x,tr_y = X[tr_inds],y[tr_inds]\n",
    "        val_x,val_y = X[val_inds],y[val_inds]\n",
    "        model,crps = BuildModel(tr_x,tr_y,val_x,val_y)\n",
    "        models.append(model)\n",
    "        print(\"the %d fold CRPS : %f\"%((k_fold+1),crps))\n",
    "        crps_csv.append(crps)\n",
    " \n",
    "print(\"mean CRPS : %f\"%np.mean(crps_csv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#Submission\n",
    "if  TRAIN_OFFLINE==False:\n",
    "    from kaggle.competitions import nflrush\n",
    "    env = nflrush.make_env()\n",
    "    iter_test = env.iter_test()\n",
    "\n",
    "    for (test_df, sample_prediction_df) in iter_test:\n",
    "        TestSet = PreprocessingTestSet(test_df,enc)\n",
    "        TestSet = scaler.transform(TestSet)\n",
    "\n",
    "        y_pred = predict(TestSet)\n",
    "        y_pred = np.clip(np.cumsum(y_pred, axis=1), 0, 1).tolist()[0]\n",
    "\n",
    "        preds_df = pd.DataFrame(data=[y_pred], columns=sample_prediction_df.columns)\n",
    "        env.predict(preds_df)\n",
    "\n",
    "    env.write_submission_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print([filename for filename in os.listdir('/kaggle/working') if '.csv' in filename])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
